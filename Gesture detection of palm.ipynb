{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import imutils #it provides an easy way for functions like resizing,rotation,translation\n",
    "import numpy as np\n",
    "from collections import deque #to keep a track of the trails of the object\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the HSV color range for skin color(which works for me, it might be different for you)\n",
    "skin_lower = (0, 10, 60) \n",
    "skin_upper = (20, 150, 255)\n",
    "\n",
    "#Used in deque structure to store no. of given buffer points\n",
    "buffer = 30 #mainly to store number of buffer points\n",
    "\n",
    "#Points deque structure storing 'buffer' no. of object coordinates\n",
    "pts = deque(maxlen = buffer)\n",
    "#Counts the minimum no. of frames to be detected where direction change occurs\n",
    "counter = 0\n",
    "#Change in direction is stored in dX, dY\n",
    "(dX, dY) = (0, 0)\n",
    "#Variable to store direction string\n",
    "direction = ''\n",
    "flag = 0\n",
    "\n",
    "#Start video capture\n",
    "video_capture = cv2.VideoCapture(0) \n",
    "\n",
    "#Sleep for 2 seconds to let camera initialize properly.\n",
    "time.sleep(2)\n",
    "\n",
    "width,height = pyautogui.size()\n",
    "\n",
    "#Loop until OpenCV window is not closed\n",
    "while True:\n",
    "    ret,frame = video_capture.read()#reading the frames\n",
    "    frame = cv2.flip(frame,1) #flipping to avoid the mirror effect\n",
    "    #resize to smaller dimension to get faster frames per seconds(you can try any to get the best speed)\n",
    "    frame = imutils.resize(frame, width = 600)\n",
    "    blurred_frame = cv2.GaussianBlur(frame, (5,5), 0) #to reduce the external noise and focus on the structure of the object\n",
    "    #Convert the frame to HSV since hsv helps in seperating the color information unlike RGB which is mainly red,blue,green\n",
    "    hsv_converted_frame = cv2.cvtColor(blurred_frame, cv2.COLOR_BGR2HSV)\n",
    "    mask = cv2.inRange(hsv_converted_frame, skin_lower, skin_upper) #segment the region under the given lower and upper range\n",
    "    #you can further erode or dilate to remove some finer details like white dots\n",
    "\n",
    "    #find all contours in the masked image\n",
    "    #you can pass cv2.CHAIN_APPROX_NONE to detect all the boundary points which will take more memory\n",
    "    _,cnts,_ = cv2.findContours(mask.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "\n",
    "    center = None #initialize centre to be zero \n",
    "\n",
    "    if(len(cnts) > 0): #checks for minimum one contour\n",
    "        #Find the contour with maximum area\n",
    "        c = max(cnts, key = cv2.contourArea)\n",
    "        #since im focussing on my palm, calculate the contour for a cicle\n",
    "        ((x, y), radius) = cv2.minEnclosingCircle(c)\n",
    "        #Calculate the centroid \n",
    "        M = cv2.moments(c)\n",
    "        center = (int(M['m10'] / M['m00']), int(M['m01'] / M['m00']))\n",
    "\n",
    "        if radius > 10:\n",
    "            #Draw circles around the object as well as its centre\n",
    "            cv2.circle(frame, (int(x), int(y)), int(radius), (0,255,255), 2) #for the outer circle\n",
    "            cv2.circle(frame, center, 5, (0,255,255), -1) #for the centroid\n",
    "            #Append the detected object in the frame to pts deque structure\n",
    "            pts.appendleft(center) #append the centroid to the deque\n",
    "\n",
    "    for i in np.arange(1, len(pts)):\n",
    "        #If no points are detected, move on.\n",
    "        if(pts[i-1] == None or pts[i] == None):\n",
    "            continue\n",
    "\n",
    "        #If atleast 10 frames have direction change, proceed\n",
    "        if counter >= 10 and i == 1 and pts[-10] is not None:\n",
    "            #Calculate the distance between the current frame and 10th frame before\n",
    "            dX = pts[-10][0] - pts[i][0]\n",
    "            dY = pts[-10][1] - pts[i][1]\n",
    "            (dirX, dirY) = ('', '')\n",
    "\n",
    "            #If distance is greater than 100 pixels, considerable direction change has occured.\n",
    "            if np.abs(dX) > 100:\n",
    "                dirX = 'Left' if np.sign(dX) == 1 else 'Right'\n",
    "\n",
    "            if np.abs(dY) > 50:\n",
    "                dirY = 'Up' if np.sign(dY) == 1 else 'Down'\n",
    "                \n",
    "            if dirX != \"\" and dirY != \"\":\n",
    "                direction = \"{}-{}\".format(dirY, dirX)\n",
    "\n",
    "            #Set direction variable to the detected direction\n",
    "            direction = dirX if dirX != '' else dirY\n",
    "\n",
    "        #Draw a trailing red line to depict motion of the object.\n",
    "        thickness = int(np.sqrt(buffer / float(i + 1)) * 2.5)\n",
    "        cv2.line(frame, pts[i - 1], pts[i], (0, 0, 255), thickness)\n",
    "        \n",
    "    cv2.putText(frame, direction, (20,40), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 3)\n",
    "\n",
    "    cv2.imshow('Window Direction Detection', frame)\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    #Update counter as the direction change has been detected.\n",
    "    counter += 1\n",
    "        \n",
    "    #If q is pressed, close the window\n",
    "    if(key == ord('q')):\n",
    "        break\n",
    "        \n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
